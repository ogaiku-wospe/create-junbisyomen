"""
å®Œå…¨ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- EXIFæƒ…å ±
- ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥
- Google Drive URL
- ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
"""

import os
import hashlib
import mimetypes
import json
from typing import Dict, Optional, Any
from datetime import datetime
from pathlib import Path

try:
    from PIL import Image
    from PIL.ExifTags import TAGS, GPSTAGS
    PILLOW_AVAILABLE = True
except ImportError:
    PILLOW_AVAILABLE = False

try:
    import PyPDF2
    PYPDF2_AVAILABLE = True
except ImportError:
    PYPDF2_AVAILABLE = False

try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

from config import *
import logging

logger = logging.getLogger(__name__)


class MetadataExtractor:
    """å®Œå…¨ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.hash_algorithm = HASH_ALGORITHM
        logger.info("âœ… MetadataExtractoråˆæœŸåŒ–å®Œäº†")
    
    def extract_complete_metadata(self, 
                                  file_path: str, 
                                  gdrive_file_info: Dict = None) -> Dict:
        """
        å®Œå…¨ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            gdrive_file_info: Google Driveã®ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
        
        Returns:
            å®Œå…¨ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        """
        logger.info(f"ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºé–‹å§‹: {os.path.basename(file_path)}")
        
        metadata = {
            # åŸºæœ¬æƒ…å ±
            "basic": self._extract_basic_metadata(file_path),
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥
            "hashes": self._calculate_hashes(file_path),
            
            # Google Driveæƒ…å ±
            "gdrive": self._extract_gdrive_metadata(gdrive_file_info),
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼å›ºæœ‰æƒ…å ±
            "format_specific": self._extract_format_specific_metadata(file_path),
            
            # æŠ½å‡ºãƒ¡ã‚¿æƒ…å ±
            "extraction_info": {
                "timestamp": get_timestamp(),
                "extractor_version": SYSTEM_VERSION,
                "extraction_method": "complete"
            }
        }
        
        logger.info(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå®Œäº†")
        return metadata
    
    def _extract_basic_metadata(self, file_path: str) -> Dict:
        """åŸºæœ¬ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        try:
            stat = os.stat(file_path)
            file_name = os.path.basename(file_path)
            file_ext = os.path.splitext(file_name)[1].lower()
            
            # MIMEã‚¿ã‚¤ãƒ—åˆ¤å®š
            mime_type, _ = mimetypes.guess_type(file_path)
            if not mime_type:
                mime_type = self._detect_mime_type(file_path)
            
            return {
                "file_name": file_name,
                "file_extension": file_ext,
                "file_size_bytes": stat.st_size,
                "file_size_human": self._format_file_size(stat.st_size),
                "mime_type": mime_type,
                "created_time": datetime.fromtimestamp(stat.st_ctime).isoformat(),
                "modified_time": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "accessed_time": datetime.fromtimestamp(stat.st_atime).isoformat(),
                "file_permissions": oct(stat.st_mode)[-3:],
                "is_readable": os.access(file_path, os.R_OK),
                "is_writable": os.access(file_path, os.W_OK)
            }
        except Exception as e:
            logger.error(f"âŒ åŸºæœ¬ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•—: {e}")
            return {}
    
    def _calculate_hashes(self, file_path: str) -> Dict:
        """è¤‡æ•°ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—"""
        try:
            hashes = {}
            
            # SHA-256
            sha256 = hashlib.sha256()
            # MD5
            md5 = hashlib.md5()
            # SHA-1
            sha1 = hashlib.sha1()
            
            with open(file_path, 'rb') as f:
                while chunk := f.read(8192):
                    sha256.update(chunk)
                    md5.update(chunk)
                    sha1.update(chunk)
            
            hashes = {
                "sha256": sha256.hexdigest(),
                "md5": md5.hexdigest(),
                "sha1": sha1.hexdigest(),
                "algorithm_primary": "sha256"
            }
            
            logger.debug(f"ãƒãƒƒã‚·ãƒ¥è¨ˆç®—å®Œäº†: SHA-256={hashes['sha256'][:16]}...")
            return hashes
            
        except Exception as e:
            logger.error(f"âŒ ãƒãƒƒã‚·ãƒ¥è¨ˆç®—å¤±æ•—: {e}")
            return {}
    
    def _extract_gdrive_metadata(self, gdrive_file_info: Dict = None) -> Dict:
        """Google Driveãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        if not gdrive_file_info:
            return {}
        
        try:
            file_id = gdrive_file_info.get('id', '')
            
            metadata = {
                "file_id": file_id,
                "file_url": GDRIVE_FILE_URL_FORMAT.format(file_id=file_id),
                "download_url": f"https://drive.google.com/uc?export=download&id={file_id}",
                "web_view_link": gdrive_file_info.get('webViewLink', ''),
                "web_content_link": gdrive_file_info.get('webContentLink', ''),
                "thumbnail_link": gdrive_file_info.get('thumbnailLink', ''),
                "icon_link": gdrive_file_info.get('iconLink', ''),
                "parent_folders": gdrive_file_info.get('parents', []),
                "owners": gdrive_file_info.get('owners', []),
                "last_modifying_user": gdrive_file_info.get('lastModifyingUser', {}),
                "created_time": gdrive_file_info.get('createdTime', ''),
                "modified_time": gdrive_file_info.get('modifiedTime', ''),
                "version": gdrive_file_info.get('version', ''),
                "original_filename": gdrive_file_info.get('originalFilename', ''),
                "md5_checksum": gdrive_file_info.get('md5Checksum', ''),
                "shared": gdrive_file_info.get('shared', False),
                "capabilities": gdrive_file_info.get('capabilities', {})
            }
            
            return metadata
            
        except Exception as e:
            logger.error(f"âŒ Google Driveãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•—: {e}")
            return {}
    
    def _extract_format_specific_metadata(self, file_path: str) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼å›ºæœ‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        file_ext = os.path.splitext(file_path)[1].lower()
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
        if file_ext in SUPPORTED_FORMATS['image']['extensions']:
            return self._extract_image_metadata(file_path)
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«
        elif file_ext == '.pdf':
            return self._extract_pdf_metadata(file_path)
        
        # Wordæ–‡æ›¸
        elif file_ext in ['.docx', '.doc']:
            return self._extract_docx_metadata(file_path)
        
        # ãã®ä»–
        else:
            return {"format": "unsupported_format_specific"}
    
    def _extract_image_metadata(self, image_path: str) -> Dict:
        """ç”»åƒã®EXIFæƒ…å ±ã‚’æŠ½å‡º"""
        if not PILLOW_AVAILABLE:
            return {"error": "PIL not available"}
        
        try:
            with Image.open(image_path) as img:
                metadata = {
                    "format": img.format,
                    "mode": img.mode,
                    "size": img.size,
                    "width": img.width,
                    "height": img.height,
                    "aspect_ratio": round(img.width / img.height, 2) if img.height > 0 else 0,
                    "resolution_dpi": img.info.get('dpi', None),
                    "color_space": self._get_color_space(img.mode),
                    "has_transparency": img.mode in ('RGBA', 'LA', 'P')
                }
                
                # EXIFæƒ…å ±
                exif_data = img._getexif() if hasattr(img, '_getexif') else None
                if exif_data:
                    exif = {}
                    for tag_id, value in exif_data.items():
                        tag = TAGS.get(tag_id, tag_id)
                        
                        # GPSæƒ…å ±ã®ç‰¹åˆ¥å‡¦ç†
                        if tag == "GPSInfo":
                            gps_data = {}
                            for t in value:
                                sub_tag = GPSTAGS.get(t, t)
                                gps_data[sub_tag] = value[t]
                            exif[tag] = gps_data
                        else:
                            # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¯æ–‡å­—åˆ—åŒ–
                            if isinstance(value, bytes):
                                try:
                                    value = value.decode('utf-8')
                                except:
                                    value = str(value)
                            exif[tag] = str(value)
                    
                    metadata['exif'] = exif
                
                return metadata
                
        except Exception as e:
            logger.error(f"âŒ ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•—: {e}")
            return {"error": str(e)}
    
    def _extract_pdf_metadata(self, pdf_path: str) -> Dict:
        """PDFã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        if not PYPDF2_AVAILABLE:
            return {"error": "PyPDF2 not available"}
        
        try:
            with open(pdf_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                
                metadata = {
                    "page_count": len(pdf_reader.pages),
                    "is_encrypted": pdf_reader.is_encrypted,
                    "pdf_version": pdf_reader.pdf_header if hasattr(pdf_reader, 'pdf_header') else None
                }
                
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±
                if pdf_reader.metadata:
                    info = {}
                    for key, value in pdf_reader.metadata.items():
                        # PyPDF2ã®ã‚­ãƒ¼ã¯'/Title'ç­‰ã®å½¢å¼
                        clean_key = key.lstrip('/')
                        info[clean_key] = str(value) if value else None
                    metadata['document_info'] = info
                
                # æœ€åˆã®ãƒšãƒ¼ã‚¸ã®ã‚µã‚¤ã‚º
                if len(pdf_reader.pages) > 0:
                    page = pdf_reader.pages[0]
                    metadata['page_size'] = {
                        'width': float(page.mediabox.width) if hasattr(page, 'mediabox') else None,
                        'height': float(page.mediabox.height) if hasattr(page, 'mediabox') else None
                    }
                
                return metadata
                
        except Exception as e:
            logger.error(f"âŒ PDFãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•—: {e}")
            return {"error": str(e)}
    
    def _extract_docx_metadata(self, docx_path: str) -> Dict:
        """Wordæ–‡æ›¸ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        if not DOCX_AVAILABLE:
            return {"error": "python-docx not available"}
        
        try:
            doc = Document(docx_path)
            
            metadata = {
                "paragraph_count": len(doc.paragraphs),
                "section_count": len(doc.sections),
                "table_count": len(doc.tables),
                "style_count": len(doc.styles)
            }
            
            # ã‚³ã‚¢ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
            core_props = doc.core_properties
            metadata['properties'] = {
                "title": core_props.title,
                "author": core_props.author,
                "subject": core_props.subject,
                "keywords": core_props.keywords,
                "comments": core_props.comments,
                "created": core_props.created.isoformat() if core_props.created else None,
                "modified": core_props.modified.isoformat() if core_props.modified else None,
                "last_modified_by": core_props.last_modified_by,
                "revision": core_props.revision,
                "category": core_props.category
            }
            
            return metadata
            
        except Exception as e:
            logger.error(f"âŒ Wordæ–‡æ›¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•—: {e}")
            return {"error": str(e)}
    
    # ================================
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¡ã‚½ãƒƒãƒ‰
    # ================================
    
    def _detect_mime_type(self, file_path: str) -> str:
        """MIMEã‚¿ã‚¤ãƒ—ã‚’æ¤œå‡º"""
        ext = os.path.splitext(file_path)[1].lower()
        
        # SUPPORTED_FORMATSã‹ã‚‰æ¤œç´¢
        for format_type, format_info in SUPPORTED_FORMATS.items():
            if ext in format_info['extensions']:
                if format_info['mime_types']:
                    return format_info['mime_types'][0]
        
        return 'application/octet-stream'
    
    def _format_file_size(self, size_bytes: int) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’äººé–“ãŒèª­ã‚ã‚‹å½¢å¼ã«å¤‰æ›"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} PB"
    
    def _get_color_space(self, mode: str) -> str:
        """PIL modeã‹ã‚‰ã‚«ãƒ©ãƒ¼ã‚¹ãƒšãƒ¼ã‚¹ã‚’å–å¾—"""
        color_spaces = {
            '1': 'Binary',
            'L': 'Grayscale',
            'P': 'Palette',
            'RGB': 'RGB',
            'RGBA': 'RGBA',
            'CMYK': 'CMYK',
            'YCbCr': 'YCbCr',
            'LAB': 'LAB',
            'HSV': 'HSV'
        }
        return color_spaces.get(mode, mode)
    
    def validate_metadata(self, metadata: Dict) -> Dict:
        """
        ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§ã‚’æ¤œè¨¼
        
        Returns:
            æ¤œè¨¼çµæœ
        """
        validation = {
            "is_valid": True,
            "completeness_score": 0.0,
            "missing_fields": [],
            "warnings": []
        }
        
        required_fields = [
            "basic.file_name",
            "basic.file_size_bytes",
            "basic.mime_type",
            "hashes.sha256",
            "gdrive.file_id",
            "gdrive.file_url"
        ]
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        present_count = 0
        for field in required_fields:
            parts = field.split('.')
            current = metadata
            exists = True
            
            for part in parts:
                if isinstance(current, dict) and part in current:
                    current = current[part]
                else:
                    exists = False
                    break
            
            if exists and current:
                present_count += 1
            else:
                validation['missing_fields'].append(field)
        
        validation['completeness_score'] = present_count / len(required_fields)
        
        if validation['completeness_score'] < QUALITY_CHECK_THRESHOLDS['metadata_coverage']:
            validation['is_valid'] = False
            validation['warnings'].append(
                f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒä¸è¶³: {validation['completeness_score']:.1%} < {QUALITY_CHECK_THRESHOLDS['metadata_coverage']:.1%}"
            )
        
        return validation
