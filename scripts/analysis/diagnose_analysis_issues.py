#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIåˆ†æçµæœã®è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã€æ©Ÿèƒ½ã€‘
- åˆ†æçµæœãŒç•°ãªã‚‹åŸå› ã‚’ç‰¹å®š
- åˆ†ææ¸ˆã¿/æœªåˆ†æè¨¼æ‹ ã®ç¢ºèª
- åˆ†æã‚¨ãƒ©ãƒ¼ã®æ¤œå‡º

ã€ä½¿ç”¨æ–¹æ³•ã€‘
    python3 scripts/analysis/diagnose_analysis_issues.py <database.json>
"""

import os
import sys
import json
from typing import Dict, List
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)


def diagnose_database(database_path: str):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®è¨ºæ–­
    
    Args:
        database_path: database.jsonã®ãƒ‘ã‚¹
    """
    print("\n" + "=" * 80)
    print("AIåˆ†æçµæœã®è¨ºæ–­")
    print("=" * 80)
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {database_path}\n")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿
    with open(database_path, 'r', encoding='utf-8') as f:
        db = json.load(f)
    
    evidence_list = db.get('evidence', [])
    total_count = len(evidence_list)
    
    print(f"ğŸ“Š åŸºæœ¬æƒ…å ±")
    print(f"   ç·è¨¼æ‹ æ•°: {total_count}ä»¶")
    print(f"   ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {db.get('version', 'N/A')}")
    print(f"   æœ€çµ‚æ›´æ–°: {db.get('metadata', {}).get('last_updated', 'N/A')}")
    
    # åˆ†æçŠ¶æ³ã‚’ç¢ºèª
    analyzed_count = 0
    unanalyzed_count = 0
    error_count = 0
    
    analyzed_list = []
    unanalyzed_list = []
    error_list = []
    
    for ev in evidence_list:
        evidence_id = ev.get('evidence_id', 'N/A')
        
        has_analyzed_content = 'analyzed_content' in ev
        has_ai_analysis = 'ai_analysis' in ev
        has_error = 'analysis_error' in ev or 'error' in ev
        
        if has_error:
            error_count += 1
            error_list.append({
                'evidence_id': evidence_id,
                'error': ev.get('analysis_error', ev.get('error', 'Unknown'))
            })
        elif has_analyzed_content or has_ai_analysis:
            analyzed_count += 1
            analyzed_list.append(evidence_id)
        else:
            unanalyzed_count += 1
            unanalyzed_list.append(evidence_id)
    
    print(f"\nğŸ“ˆ åˆ†æçŠ¶æ³")
    print(f"   âœ… åˆ†ææ¸ˆã¿: {analyzed_count}ä»¶")
    print(f"   â³ æœªåˆ†æ: {unanalyzed_count}ä»¶")
    print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶")
    
    # æœªåˆ†æè¨¼æ‹ ã®è©³ç´°
    if unanalyzed_list:
        print(f"\nâ³ æœªåˆ†æè¨¼æ‹ ã®ä¸€è¦§:")
        for i, evidence_id in enumerate(unanalyzed_list, 1):
            # è©²å½“ã™ã‚‹è¨¼æ‹ ã‚’å–å¾—
            ev = next((e for e in evidence_list if e.get('evidence_id') == evidence_id), None)
            if ev:
                filename = ev.get('original_filename', 'N/A')
                print(f"   {i}. {evidence_id} ({filename})")
    
    # ã‚¨ãƒ©ãƒ¼è¨¼æ‹ ã®è©³ç´°
    if error_list:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼è¨¼æ‹ ã®è©³ç´°:")
        for i, err_info in enumerate(error_list, 1):
            print(f"   {i}. {err_info['evidence_id']}")
            print(f"      ã‚¨ãƒ©ãƒ¼: {err_info['error']}")
    
    # åˆ†æå†…å®¹ã®å“è³ªãƒã‚§ãƒƒã‚¯
    print(f"\nğŸ” åˆ†æå†…å®¹ã®å“è³ªãƒã‚§ãƒƒã‚¯")
    
    for i, ev in enumerate(evidence_list[:5], 1):  # æœ€åˆã®5ä»¶
        evidence_id = ev.get('evidence_id', 'N/A')
        filename = ev.get('original_filename', 'N/A')
        
        print(f"\n   {i}. {evidence_id} ({filename})")
        print(f"      " + "-" * 70)
        
        # complete_metadataã®ãƒã‚§ãƒƒã‚¯
        if 'complete_metadata' in ev:
            meta = ev['complete_metadata']
            print(f"      âœ… complete_metadata: å­˜åœ¨")
            print(f"         - basic: {'âœ…' if 'basic' in meta else 'âŒ'}")
            print(f"         - hashes: {'âœ…' if 'hashes' in meta else 'âŒ'}")
            print(f"         - exif: {'âœ…' if 'exif' in meta else 'âŒ'}")
        else:
            print(f"      âŒ complete_metadata: å­˜åœ¨ã—ãªã„")
        
        # analyzed_contentã®ãƒã‚§ãƒƒã‚¯
        if 'analyzed_content' in ev:
            content = ev['analyzed_content']
            if isinstance(content, dict):
                print(f"      âœ… analyzed_content: è¾æ›¸å½¢å¼ ({len(content)} keys)")
                
                # ä¸»è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
                required_fields = ['content_summary', 'content_type', 'text_content']
                for field in required_fields:
                    if field in content:
                        value = content[field]
                        if isinstance(value, str):
                            preview = value[:50] + '...' if len(value) > 50 else value
                            print(f"         - {field}: {preview}")
                        else:
                            print(f"         - {field}: {type(value).__name__}")
                    else:
                        print(f"         - {field}: âŒ å­˜åœ¨ã—ãªã„")
            else:
                print(f"      âš ï¸ analyzed_content: {type(content).__name__}")
        else:
            print(f"      âŒ analyzed_content: å­˜åœ¨ã—ãªã„")
        
        # ai_analysisã®ãƒã‚§ãƒƒã‚¯
        if 'ai_analysis' in ev:
            ai = ev['ai_analysis']
            print(f"      âœ… ai_analysis: å­˜åœ¨ ({len(ai)} keys)")
        else:
            print(f"      âŒ ai_analysis: å­˜åœ¨ã—ãªã„")
    
    # è¨ºæ–­çµæœã‚µãƒãƒªãƒ¼
    print(f"\n" + "=" * 80)
    print("ğŸ“‹ è¨ºæ–­çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    
    if unanalyzed_count == total_count:
        print("âš ï¸  ã™ã¹ã¦ã®è¨¼æ‹ ãŒæœªåˆ†æã§ã™")
        print("\nã€åŸå› ã®å¯èƒ½æ€§ã€‘")
        print("  1. AIåˆ†æãŒã¾ã å®Ÿè¡Œã•ã‚Œã¦ã„ãªã„")
        print("  2. åˆ†æå‡¦ç†ãŒã‚¨ãƒ©ãƒ¼ã§ä¸­æ–­ã•ã‚ŒãŸ")
        print("  3. database.jsonãŒå¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å¯èƒ½æ€§")
        print("\nã€å¯¾å‡¦æ–¹æ³•ã€‘")
        print("  1. run_phase1_multi.py ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€Œ2. è¨¼æ‹ åˆ†æã€ã‚’å®Ÿè¡Œ")
        print("  2. è¨¼æ‹ ç•ªå·ã‚’æŒ‡å®šã—ã¦AIåˆ†æã‚’å®Ÿè¡Œ")
    
    elif unanalyzed_count > 0:
        print(f"âš ï¸  {unanalyzed_count}ä»¶ã®è¨¼æ‹ ãŒæœªåˆ†æã§ã™")
        print("\nã€å¯¾å‡¦æ–¹æ³•ã€‘")
        print("  - æœªåˆ†æè¨¼æ‹ ã«å¯¾ã—ã¦AIåˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    
    if error_count > 0:
        print(f"\nâŒ {error_count}ä»¶ã®è¨¼æ‹ ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™")
        print("\nã€å¯¾å‡¦æ–¹æ³•ã€‘")
        print("  1. ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèª")
        print("  2. ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ãªã„ã‹ç¢ºèª")
        print("  3. å†åº¦AIåˆ†æã‚’å®Ÿè¡Œ")
    
    if analyzed_count == total_count:
        print("âœ… ã™ã¹ã¦ã®è¨¼æ‹ ãŒæ­£å¸¸ã«åˆ†æã•ã‚Œã¦ã„ã¾ã™")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 diagnose_analysis_issues.py <database.json>")
        sys.exit(1)
    
    database_path = sys.argv[1]
    
    if not os.path.exists(database_path):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {database_path}")
        sys.exit(1)
    
    diagnose_database(database_path)


if __name__ == '__main__':
    main()
