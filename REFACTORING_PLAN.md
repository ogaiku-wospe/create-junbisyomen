# AIåˆ†æã‚¨ãƒ³ã‚¸ãƒ³ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°è¨ˆç”»

## ğŸ¯ ç›®çš„

1. **OpenAI APIå®Œå…¨å‰Šé™¤** - ChatGPT APIã¯ä¸è¦
2. **Claude Vision APIå°‚ç”¨åŒ–** - ã‚ˆã‚Šç¢ºå®Ÿãªåˆ†æ
3. **æ®µéšçš„åˆ†æã®å®Ÿè£…** - å„ã‚¹ãƒ†ãƒƒãƒ—ã§çµæœã‚’æ¤œè¨¼

## âœ… å®Œäº†ã—ãŸä½œæ¥­ï¼ˆPart 1ï¼‰

### ã‚³ãƒŸãƒƒãƒˆ: 27a91d3

- âœ… `import openai` å‰Šé™¤
- âœ… OpenAI clientåˆæœŸåŒ–å‰Šé™¤ (`self.client`)
- âœ… Anthropic Claude APIã‚’å¿…é ˆåŒ–
- âœ… ä¸­é–“çµæœä¿å­˜ç”¨ã® `self.intermediate_results` è¿½åŠ 
- âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ–‡å­—åˆ—æ›´æ–°

**çµæœ**: 130è¡Œå‰Šé™¤ã€41è¡Œè¿½åŠ 

## ğŸ”„ æ®‹ã‚Šã®ä½œæ¥­

### Part 2: OpenAI APIå‘¼ã³å‡ºã—ã‚’å®Œå…¨å‰Šé™¤

**å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«**: `src/ai_analyzer_complete.py`

#### å‰Šé™¤ãŒå¿…è¦ãªç®‡æ‰€

1. **`_analyze_with_vision` ãƒ¡ã‚½ãƒƒãƒ‰å†…** (ç¾åœ¨529è¡Œä»¥é™ã«æ­»ã‚³ãƒ¼ãƒ‰ã‚ã‚Š)
   - lines 531-720: OpenAI APIçµæœå‡¦ç†ã‚³ãƒ¼ãƒ‰å…¨ä½“
   - OpenAIã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒªã‚·ãƒ¼æ‹’å¦ãƒã‚§ãƒƒã‚¯
   - OpenAIâ†’Claude Visionâ†’Claude Textã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³

2. **`_analyze_with_text` ãƒ¡ã‚½ãƒƒãƒ‰å†…** (line 1121ä»˜è¿‘)
   - OpenAI APIå‘¼ã³å‡ºã—
   - GPT-4 Turboãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ç®‡æ‰€

3. **ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«**:
   - `src/evidence_editor_ai.py` (lines 213, 279)

#### ç½®ãæ›ãˆæ–¹æ³•

```python
# æ—§: OpenAI APIå‘¼ã³å‡ºã—
response = self.client.chat.completions.create(
    model=OPENAI_MODEL,
    messages=[...],
    max_tokens=OPENAI_MAX_TOKENS
)
result = response.choices[0].message.content

# æ–°: Claude APIã®ã¿
result = self._analyze_with_claude_stepwise(...)
```

### Part 3: æ®µéšçš„åˆ†æãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè£…

#### æ–°ãƒ¡ã‚½ãƒƒãƒ‰: `_analyze_with_claude_stepwise`

```python
def _analyze_with_claude_stepwise(self, 
                                   image_paths: List[str],
                                   prompt: str,
                                   file_type: str,
                                   pdf_text: str = "") -> Dict:
    """
    Claude Vision APIã§æ®µéšçš„åˆ†æ
    
    ã‚¹ãƒ†ãƒƒãƒ—1: å„ãƒšãƒ¼ã‚¸ã‚’å€‹åˆ¥ã«åˆ†æ
    ã‚¹ãƒ†ãƒƒãƒ—2: ãƒšãƒ¼ã‚¸é–“ã®ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯
    ã‚¹ãƒ†ãƒƒãƒ—3: å…¨ä½“ã‚’çµ±åˆåˆ†æ
    ã‚¹ãƒ†ãƒƒãƒ—4: JSONå½¢å¼ã§çµæœã‚’è¿”ã™
    
    å„ã‚¹ãƒ†ãƒƒãƒ—ã§ä¸­é–“çµæœã‚’ self.intermediate_results ã«ä¿å­˜
    """
    logger.info(f"ğŸ“Š æ®µéšçš„åˆ†æé–‹å§‹: {len(image_paths)}ãƒšãƒ¼ã‚¸")
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒšãƒ¼ã‚¸å˜ä½åˆ†æ
    page_results = []
    for i, image_path in enumerate(image_paths, 1):
        logger.info(f"  ğŸ“„ ãƒšãƒ¼ã‚¸{i}åˆ†æä¸­...")
        
        # ãƒšãƒ¼ã‚¸å˜ç‹¬ã§åˆ†æ
        page_prompt = f"""
Analyze page {i} of {len(image_paths)} from this legal document.

Extract:
1. OCR text from this page only
2. Key information (names, addresses, dates, amounts)
3. Document type indicators (contract, notice, certificate, etc.)

Return as JSON.
"""
        
        page_result = self._analyze_single_page_with_claude(image_path, page_prompt)
        page_results.append({
            'page': i,
            'result': page_result,
            'image_path': image_path
        })
        
        # ä¸­é–“çµæœã‚’ä¿å­˜
        self.intermediate_results[f'page_{i}'] = page_result
        logger.info(f"  âœ… ãƒšãƒ¼ã‚¸{i}åˆ†æå®Œäº†")
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒšãƒ¼ã‚¸é–“ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
    logger.info(f"  ğŸ” ãƒšãƒ¼ã‚¸é–“ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯...")
    consistency_check = self._check_page_consistency(page_results, pdf_text)
    self.intermediate_results['consistency_check'] = consistency_check
    
    if not consistency_check['is_consistent']:
        logger.warning(f"  âš ï¸ ãƒšãƒ¼ã‚¸é–“ã®ä¸æ•´åˆã‚’æ¤œå‡º: {consistency_check['issues']}")
    else:
        logger.info(f"  âœ… ãƒšãƒ¼ã‚¸é–“ã®ä¸€è²«æ€§ç¢ºèª")
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: å…¨ä½“çµ±åˆåˆ†æ
    logger.info(f"  ğŸ“‹ å…¨ä½“çµ±åˆåˆ†æä¸­...")
    
    # å…¨ãƒšãƒ¼ã‚¸ã®æƒ…å ±ã‚’çµ±åˆã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    combined_prompt = self._build_combined_prompt(prompt, page_results, consistency_check)
    
    # å…¨ç”»åƒã¨çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§Claude Vision APIã‚’å‘¼ã³å‡ºã—
    final_result = self._analyze_with_claude_multi_page(image_paths, combined_prompt)
    
    # ã‚¹ãƒ†ãƒƒãƒ—4: JSONå½¢å¼ã§è¿”ã™
    self.intermediate_results['final_result'] = final_result
    
    logger.info(f"  âœ… æ®µéšçš„åˆ†æå®Œäº†")
    return final_result
```

#### æ–°ãƒ¡ã‚½ãƒƒãƒ‰: `_analyze_single_page_with_claude`

```python
def _analyze_single_page_with_claude(self, image_path: str, prompt: str) -> Dict:
    """
    å˜ä¸€ãƒšãƒ¼ã‚¸ã‚’Claude Vision APIã§åˆ†æ
    """
    # ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    with open(image_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode('utf-8')
    
    mime_type = self._get_mime_type(image_path)
    
    # Claude Vision APIå‘¼ã³å‡ºã—
    try:
        response = self.anthropic_client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2048,  # ãƒšãƒ¼ã‚¸å˜ä½ãªã®ã§çŸ­ã‚
            messages=[{
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": mime_type,
                            "data": image_data
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }]
        )
        
        result_text = response.content[0].text
        
        # JSONè§£æ
        return self._parse_json_safely(result_text)
        
    except Exception as e:
        logger.error(f"Claude Vision APIå‘¼ã³å‡ºã—å¤±æ•—: {e}")
        return {'error': str(e)}
```

#### æ–°ãƒ¡ã‚½ãƒƒãƒ‰: `_check_page_consistency`

```python
def _check_page_consistency(self, page_results: List[Dict], pdf_text: str = "") -> Dict:
    """
    ãƒšãƒ¼ã‚¸é–“ã®ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯
    
    ç¢ºèªé …ç›®:
    1. åŒã˜æ–‡æ›¸ã‹ï¼ˆæ–‡æ›¸ã‚¿ã‚¤ãƒ—ã€å·®å‡ºäººã€å—å–äººãªã©ï¼‰
    2. ãƒšãƒ¼ã‚¸ç•ªå·ã®é€£ç¶šæ€§
    3. PDFãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã¨ã®ä¸€è‡´ç‡
    """
    import re
    
    consistency = {
        'is_consistent': True,
        'issues': [],
        'document_type': None,
        'sender': None,
        'recipient': None
    }
    
    # ãƒšãƒ¼ã‚¸1ã‹ã‚‰æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã‚’å–å¾—
    if len(page_results) > 0:
        page1 = page_results[0]['result']
        consistency['document_type'] = page1.get('document_type')
        consistency['sender'] = page1.get('sender')
        consistency['recipient'] = page1.get('recipient')
    
    # å„ãƒšãƒ¼ã‚¸ã®æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã‚’ç¢ºèª
    for page_result in page_results[1:]:
        page_doc_type = page_result['result'].get('document_type')
        if page_doc_type and page_doc_type != consistency['document_type']:
            consistency['is_consistent'] = False
            consistency['issues'].append(
                f"ãƒšãƒ¼ã‚¸{page_result['page']}ã®æ–‡æ›¸ã‚¿ã‚¤ãƒ—ãŒç•°ãªã‚‹: "
                f"{consistency['document_type']} vs {page_doc_type}"
            )
    
    # PDFãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã¨ã®ä¸€è‡´ç¢ºèª
    if pdf_text:
        # ãƒšãƒ¼ã‚¸1ã®OCRãƒ†ã‚­ã‚¹ãƒˆã¨PDFæŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒ
        page1_ocr = page_results[0]['result'].get('ocr_text', '')
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ç‡
        patterns = [
            r'\d{3}-?\d{4}',  # éƒµä¾¿ç•ªå·
            r'\d{2,4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥',  # æ—¥ä»˜
        ]
        
        pdf_keywords = set()
        for pattern in patterns:
            pdf_keywords.update(re.findall(pattern, pdf_text))
        
        ocr_keywords = set()
        for pattern in patterns:
            ocr_keywords.update(re.findall(pattern, page1_ocr))
        
        if pdf_keywords and len(pdf_keywords & ocr_keywords) / len(pdf_keywords) < 0.5:
            consistency['issues'].append(
                f"ãƒšãƒ¼ã‚¸1ã®OCRãƒ†ã‚­ã‚¹ãƒˆã¨PDFæŠ½å‡ºã®ä¸€è‡´ç‡ãŒä½ã„"
            )
    
    return consistency
```

#### æ–°ãƒ¡ã‚½ãƒƒãƒ‰: `_build_combined_prompt`

```python
def _build_combined_prompt(self, 
                           original_prompt: str,
                           page_results: List[Dict],
                           consistency_check: Dict) -> str:
    """
    ãƒšãƒ¼ã‚¸å˜ä½ã®åˆ†æçµæœã‚’çµ±åˆã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
    """
    # ãƒšãƒ¼ã‚¸å˜ä½ã®æƒ…å ±ã‚’ã¾ã¨ã‚ã‚‹
    pages_summary = []
    for page_result in page_results:
        page_num = page_result['page']
        result = page_result['result']
        
        summary = f"""
Page {page_num}:
- Document type: {result.get('document_type', 'Unknown')}
- Key entities: {result.get('key_entities', [])}
- OCR text (first 200 chars): {result.get('ocr_text', '')[:200]}
"""
        pages_summary.append(summary)
    
    # çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    combined_prompt = f"""
CONTEXT: This document has {len(page_results)} pages. Each page has been pre-analyzed.

PAGE-BY-PAGE SUMMARY:
{''.join(pages_summary)}

CONSISTENCY CHECK:
- Document consistency: {'âœ… Consistent' if consistency_check['is_consistent'] else 'âš ï¸ Inconsistent'}
- Issues: {', '.join(consistency_check['issues']) if consistency_check['issues'] else 'None'}

TASK:
Based on the above page-level analysis, now perform a comprehensive analysis of the entire document.

{original_prompt}

IMPORTANT:
- Use the page-level OCR text provided above
- Ensure the analysis is consistent across all pages
- If there are inconsistencies, explain them in the analysis
"""
    
    return combined_prompt
```

### Part 4: JSONè§£æã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–

æ—¢ã«å®Ÿè£…æ¸ˆã¿ã® `_parse_json_safely` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ´»ç”¨ã—ã€æ®µéšçš„åˆ†æã®å„ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨ã™ã‚‹ã€‚

```python
def _parse_json_safely(self, text: str) -> Dict:
    """
    JSONè§£æã‚’å®‰å…¨ã«è¡Œã†ï¼ˆæ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ”¹å–„ï¼‰
    """
    # æ—¢å­˜ã®ä¿®å¾©ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
    # ã•ã‚‰ã«æ”¹å–„: è¤‡æ•°ã®ä¿®å¾©æˆ¦ç•¥ã‚’è©¦ã™
    pass
```

## ğŸ“Š æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

### Beforeï¼ˆç¾åœ¨ï¼‰

```
OpenAI APIå‘¼ã³å‡ºã—
  â†“ æ‹’å¦ã•ã‚Œã‚‹
Claude Vision APIï¼ˆå…¨ãƒšãƒ¼ã‚¸ä¸€æ‹¬ï¼‰
  â†“ JSONè§£æã‚¨ãƒ©ãƒ¼
å¤±æ•—
```

### Afterï¼ˆæ”¹å–„å¾Œï¼‰

```
ã‚¹ãƒ†ãƒƒãƒ—1: ãƒšãƒ¼ã‚¸1åˆ†æ â†’ æˆåŠŸ âœ…
ã‚¹ãƒ†ãƒƒãƒ—1: ãƒšãƒ¼ã‚¸2åˆ†æ â†’ æˆåŠŸ âœ…
ã‚¹ãƒ†ãƒƒãƒ—1: ãƒšãƒ¼ã‚¸3åˆ†æ â†’ æˆåŠŸ âœ…
ã‚¹ãƒ†ãƒƒãƒ—2: ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯ â†’ å•é¡Œãªã— âœ…
ã‚¹ãƒ†ãƒƒãƒ—3: å…¨ä½“çµ±åˆåˆ†æ â†’ æˆåŠŸ âœ…
ã‚¹ãƒ†ãƒƒãƒ—4: JSONå½¢å¼åŒ– â†’ æˆåŠŸ âœ…
```

## ğŸ”§ å®Ÿè£…æ‰‹é †

1. **Part 2ã‚’å®Œäº†** - OpenAI APIã‚³ãƒ¼ãƒ‰å…¨å‰Šé™¤
2. **Part 3ã‚’å®Ÿè£…** - æ®µéšçš„åˆ†æãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ 
3. **ãƒ†ã‚¹ãƒˆ** - tmp_ko_004ã§å‹•ä½œç¢ºèª
4. **ã‚³ãƒŸãƒƒãƒˆï¼†ãƒ—ãƒƒã‚·ãƒ¥** - PRæ›´æ–°

## ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼æ§˜ã¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

ç¾åœ¨ã€OpenAI APIã®å‰Šé™¤ä½œæ¥­ã‚’é€²ã‚ã¦ã„ã¾ã™ï¼ˆPart 1å®Œäº†ï¼‰ã€‚

æ®‹ã‚Šã®ä½œæ¥­ã¯å¤§ãã„ãŸã‚ã€ä»¥ä¸‹ã®é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™ï¼š

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³1: å®Œå…¨å®Ÿè£…ï¼ˆæ¨å¥¨ã€æ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰
- OpenAI APIå®Œå…¨å‰Šé™¤
- æ®µéšçš„åˆ†æãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè£…
- å…¨æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³2: æœ€å°é™ã®ä¿®æ­£ï¼ˆé€Ÿã„ï¼‰
- OpenAI APIã‚³ãƒ¼ãƒ«ã‚’å…¨ã¦Claude APIã«ç½®ãæ›ãˆ
- æ®µéšçš„åˆ†æã¯å¾Œå›ã—
- å‹•ä½œã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’å„ªå…ˆ

ã©ã¡ã‚‰ã‚’å¸Œæœ›ã•ã‚Œã¾ã™ã‹ï¼Ÿ
